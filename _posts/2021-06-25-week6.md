---
layout: post
title: Week 6!
---

Most of this week was spent touching up our study materials. I can’t wait for the IRB to approve our study, so we can start recruiting participants and run it soon. Right now, I am concerned that coordinating times where two participants, Isabelle and I are available will be difficult. Another complication is that we will have to match hearing and DHH/HL participants for topics of common interest. I also hope that our stringent headphone requirement does not eliminate too many potential participants’ eligibility for our study. I think the best case scenario right now is that we will finish conducting study sessions by the end of week 8. That does not leave us a lot of time to analyze the data we’ve collected which I anticipate will be time consuming since we still do not know exactly what we’ll be looking for. 

Yesterday, we had a program-wide meeting where each group presented their materials and methods for their study. I was rather impressed with Web RTC’s setup. Their transition from stimuli to survey and so on was seamless, and it looks like they put in a lot of effort to create their stimuli. Seeing Sign Detection’s application demo was also very interesting. I was surprised the application showed more of a gradient for sign detection rather than a binary yes/no. I also enjoyed watching Caption UI/UX’s memoji and paralinguistic description examples for captions. I think I would personally prefer the paralinguistic description as opposed to the memoji since I find the memoji emotions a bit hard to discern and kind of distracting, but I am curious to see what their group finds. Finally, I think Caption Metrics’s research question is an important one, and I think their approach of tackling assessments of captioning accuracy from the user perspective will be insightful. One concern I have for their study is participant fatigue, however, because they’re showing them twenty videos with a survey after each video for one hour. But perhaps each video is short, so it will be okay. I forgot to ask the Web RTC team, but I am wondering how they plan to analyze their recordings for “participant reactions.” I’m not sure whether they mean eye gaze or facial expressions. All in all, it looks like all teams have compelling study designs and I look forward to our next presentation of results! 

A social hour is happening in 30 minutes, and I am kind of bummed I will be missing it due to a dentist appointment. Hope another one happens before the end of the internship! 
